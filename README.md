# Feature Engineered Transaction Risk Model


## ğŸ“Œ Overview
This project builds **an auditâ€‘focused transaction risk scoring engine** that ranks origin accounts based on their behavior in a large synthetic financial transactions dataset. The goal is to help internal audit and fraud teams **prioritize which accounts to review first**.

The pipeline:

* Aggregates raw transactions to the **account** level.
* Engineers **auditâ€‘relevant features** such as volume, volatility, transactionâ€‘type mix, and fraud rate.
* Computes an interpretable **risk score** and **highâ€‘risk flag** for each origin account.
* Generates plots and tables to explain why accounts are labeled high risk.

---

ğŸ“‘ Table of Contents
Project Objectives

Project Structure

Data and Features

Risk Scoring Model

Analysis and Visualizations

Tools and Libraries

Possible Extensions

---

## ğŸ¯ Project Objectives
* Transform raw transactionâ€‘level data into accountâ€‘level risk indicators for internal audit.
* Design a transparent, explainable scoring model instead of a blackâ€‘box classifier.
* Handle largeâ€‘scale synthetic financial data using a reproducible Python pipeline.
* Provide notebooks and plots that communicate findings to nonâ€‘technical audit stakeholders.

---

ğŸ“‚ Project Structure
text
audit-risk-model/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ transactions.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ origin_account_features.csv
â”‚       â””â”€â”€ origin_account_features_scored.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â””â”€â”€ 02_risk_scoring_model.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ features.py
â”‚   â””â”€â”€ model.py
â””â”€â”€ run_pipeline.py

* `data/raw/transactions.csv` â€“ synthetic transactionâ€‘level dataset.
* `data/processed/origin_account_features.csv` â€“ originâ€‘account features after aggregation.
* `data/processed/origin_account_features_scored.csv` â€“ features plus risk scores and flags.
* `01_exploration.ipynb` â€“ quick EDA of the raw transactions.
* `02_risk_scoring_model.ipynb` â€“ scoring logic, highâ€‘risk flags, plots, and interpretation.
* `src/data_prep.py` â€“ `load_transactions()` with optional sampling.
* `src/features.py` â€“ `build_origin_account_features()` (groupby by origin account).
* `src/model.py` â€“ `add_risk_score()` (scaling + weighted risk score).
* `run_pipeline.py` â€“ orchestrates the full pipeline and prints top highâ€‘risk accounts.

---

ğŸ“Š Data and Features
The raw dataset simulates mobile money transactions with fields like `step`, `type`, `amount`, `nameOrig`, `nameDest`, balances, and fraud labels.

Key raw fields:

* `step` â€“ simulated time step (hour index).
* `type` â€“ transaction type (PAYMENT, TRANSFER, CASH_OUT, DEBIT, etc.).
* `amount` â€“ transaction amount.
* `nameOrig` â€“ origin account.
* `nameDest` â€“ destination account.
* `oldbalanceOrg`, `newbalanceOrg`, `oldbalanceDest`, `newbalanceDest`.
* `isFraud`, `isFlaggedFraud` â€“ fraud indicators.

Transactions are aggregated by `nameOrig` into originâ€‘accountâ€‘level features:

* `txn_count` â€“ number of transactions.
* `total_amount` â€“ total value sent.
* `avg_amount`, `std_amount`, `max_amount`, `min_amount`.
* `amount_volatility` â€“ `std_amount` / `avg_amount`.
* `payment_ratio` â€“ share of transactions that are PAYMENT.
* `transfer_ratio` â€“ share of transactions that are TRANSFER.
* `cashout_ratio` â€“ share of transactions that are CASH_OUT.
* `debit_ratio` â€“ share of transactions that are DEBIT.
* `fraud_rate` â€“ average of isFraud for the account.

These features are written to `origin_account_features.csv` and reused by both the pipeline and the analysis notebook.

---

## ğŸ§  Risk Scoring Model
The risk model is deliberately **simple and auditâ€‘friendly**.

### Feature Scaling
Selected features are scaled to [0,1] using `MinMaxScaler`:

* `txn_count`
* `total_amount`
* `amount_volatility`
* `fraud_rate`

### Weighted Composite Score
A linear risk score is computed as a weighted sum:

* 0.2 Ã— scaled `txn_count`
* 0.2 Ã— scaled `total_amount`
* 0.3 Ã— scaled `amount_volatility`
* 0.3 Ã— scaled `fraud_rate`

This emphasizes accounts that:

* Move **a lot of money**,
* Have **volatile transaction patterns**, and
* Show **higher historical fraud rate**.

The resulting `risk_score` is stored in `origin_account_features_scored.csv`.

### Highâ€‘Risk Flag
To make the score actionable, the engine defines a **highâ€‘risk flag**:

* Sort accounts by `risk_score` (descending).
* Label the **top 20%** as high risk with a binary `high_risk_flag` column.

This gives audit a clear list of accounts to prioritize for testing.

---

## ğŸ” Analysis and Visualizations

`02_risk_scoring_model.ipynb` provides:

* **Summary statistics** of `risk_score`.
* A **histogram**: â€œDistribution of Audit Risk Scores by Origin Account.â€
* Tables showing **example highâ€‘risk accounts vs lowâ€‘risk accounts**, including:

* `txn_count`
* `total_amount`
* `amount_volatility`
* `fraud_rate`
* `risk_score`
* `high_risk_flag`

---

## ğŸ›  Tools and Libraries

* Python
* pandas, NumPy
* scikitâ€‘learn (MinMaxScaler)
* Matplotlib
* Jupyter Notebook / Cursor

---

ğŸš€ Possible Extensions
* Train a supervised model (e.g., logistic regression) to predict `isFraud` or `high_risk_flag`.
* Add **timeâ€‘window features** (recent spike in activity vs longâ€‘term behavior).
* Build a **Streamlit or Dash app** for auditors to filter and investigate highâ€‘risk accounts.
* Tune weights in the risk score with domain input from audit or credit risk teams.
